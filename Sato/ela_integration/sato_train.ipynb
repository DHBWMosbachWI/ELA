{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# This Notebook is for training new Sato models with other datacorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enviroment set-up\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"D:\\\\20120321_DHBW_AZUREML\\\\sato\")\n",
    "sys.path.append(\"D:\\\\20120321_DHBW_AZUREML\\\\sato\\\\model\")\n",
    "from os.path import join\n",
    "\n",
    "# set env-var\n",
    "os.environ['BASEPATH'] = 'D:\\\\20120321_DHBW_AZUREML\\\\sato'\n",
    "os.environ['RAW_DIR'] = '/mnt/batch/tasks/shared/LS_root/mounts/clusters/dhbwmlc-ds12-v2/code/Users/svenlangenecker/viznet-master/raw' # path to the raw data\n",
    "os.environ['SHERLOCKPATH'] = os.environ['BASEPATH']+'\\\\sherlock'\n",
    "os.environ['EXTRACTPATH'] = os.environ['BASEPATH']+'\\\\extract'\n",
    "#os.environ['PYTHONPATH'] = os.environ['PYTHONPATH']+':'+os.environ['SHERLOCKPATH']\n",
    "#os.environ['PYTHONPATH'] = os.environ['PYTHONPATH']+':'+os.environ['BASEPATH']\n",
    "os.environ['TYPENAME'] = 'type_gittables_abstraction'\n",
    "\n",
    "# set requirements\n",
    "#from azureml.core import Workspace, Environment\n",
    "#ws = Workspace.from_config()\n",
    "#Environment(name='satoEnv')\n",
    "\n",
    "#satoEnv = Environment.from_pip_requirements(name=\"satoEnv\",file_path=\"../requirements.txt\")\n",
    "#satoEnv.register(workspace=ws)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Column feature extraction\n",
    "%run ../extract/extract_features.py public_bi_benchmark -f sherlock -n 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train test\n",
    "%run ../extract/split_train_test.py --corpus_list gittables-abstraction-tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain Sherlock with turl output-size-layer\n",
    "%run ../model/train_sherlock.py -c ../model/params/turl/sherlock_retrain.txt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Sato-Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation of Sato, first try in column-level split\n",
    "%run ../model/train_CRF_LC.py -c ../model/params/public_bi/CRF+LDA_eval.txt --model_list \"model.pt\" \"CRF+LDA_pathL.pt\" \"CRF+LDA_pre.pt\" --train_percent \"train100\" --test_percent \"test100\" --comment \"sato_baseline_column_level_split_test20\" --column_level_split_file_path \"D:\\\\semantic_data_lake\\\\semantic_data_lake\\\\data\\\\extract\\\\out\\\\labeled_unlabeled_test_split\\\\public_bi_1_absolute_20.0.json\"\n",
    "#%run ../model/train_CRF_LC.py -c ../model/params/publicbi/CRF+LDA_eval.txt --model_list \"CRF_pre.pt\" \"CRF+LDA_retrain_train80_test20.pt\" --train_percent \"train100\" --test_percent \"test100\" --comment \"column-level-split\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation of Sherlock, first try in column-level split\n",
    "%run ../model/train_sherlock.py -c ../model/params/public_bi/sherlock_eval.txt --model_list \"all_None.pt\" --comment \"sherlock_baseline_column_level_split_test20\" --column_level_split_file_path \"D:\\\\semantic_data_lake\\\\semantic_data_lake\\\\data\\\\extract\\\\out\\\\labeled_unlabeled_test_split\\\\public_bi_1_absolute_20.0.json\"\n",
    "#%run ../model/train_sherlock.py -c ../model/params/publicbi/sherlock_eval.txt --model_list \"all_None.pt\" --comment \"sherlock_baseline_column_level_split_test20\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Sato + small set of labeled training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"Test{+\"Test\"}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.concatenate((np.arange(0,6,1),np.arange(6,11,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# set env-var\n",
    "os.environ['BASEPATH'] = 'D:\\\\20120321_DHBW_AZUREML\\\\sato'\n",
    "os.environ['RAW_DIR'] = '/mnt/batch/tasks/shared/LS_root/mounts/clusters/dhbwmlc-ds12-v2/code/Users/svenlangenecker/viznet-master/raw' # path to the raw data\n",
    "os.environ['SHERLOCKPATH'] = os.environ['BASEPATH']+'\\\\sherlock'\n",
    "os.environ['EXTRACTPATH'] = os.environ['BASEPATH']+'\\\\extract'\n",
    "#os.environ['PYTHONPATH'] = os.environ['PYTHONPATH']+':'+os.environ['SHERLOCKPATH']\n",
    "#os.environ['PYTHONPATH'] = os.environ['PYTHONPATH']+':'+os.environ['BASEPATH']\n",
    "os.environ['TYPENAME'] = 'type78'\n",
    "\n",
    "#for index,percent in enumerate(np.arange(15,55,5)):\n",
    "for index, percent in enumerate(np.arange(1,2,1)):\n",
    "    # if index != 0:\n",
    "    #     continue\n",
    "    comment = f\"labeled{percent}_unlabeledAbsolute_test{20}\"\n",
    "    column_level_split_file_path = f\"D:\\\\semantic_data_lake\\\\semantic_data_lake\\\\data\\\\extract\\\\out\\\\labeled_unlabeled_test_split\\\\public_bi_{percent}_absolute_20.0.json\"\n",
    "    pretrained_shelock_path = f\"sherlock_retrain_labeled{percent}_unlabeledAbsolute_test{20.0}.pt\"\n",
    "    pretrained_CRF_LDA_path = f\"CRF+LDA_retrain_labeled{percent}_unlabeledAbsolute_test{20.0}.pt\"\n",
    "    \n",
    "    # retrain sherlock\n",
    "    %run ../model/train_sherlock.py -c ../model/params/public_bi/sherlock_retrain.txt  --comment {comment} --column_level_split_file_path {column_level_split_file_path}\n",
    "    # retrain sato\n",
    "    %run ../model/train_CRF_LC.py -c ../model/params/public_bi/CRF+LDA_retrain.txt --pre_trained_sherlock_path {pretrained_shelock_path} --comment {comment} --column_level_split_file_path {column_level_split_file_path}\n",
    "    # validate sato\n",
    "    %run ../model/train_CRF_LC.py -c ../model/params/public_bi/CRF+LDA_eval.txt --model_list {pretrained_CRF_LDA_path} --comment {\"eval_\"+comment} --column_level_split_file_path {column_level_split_file_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Sato retrained with EmbClus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# set env-var\n",
    "os.environ['BASEPATH'] = 'D:\\\\20120321_DHBW_AZUREML\\\\sato'\n",
    "os.environ['RAW_DIR'] = '/mnt/batch/tasks/shared/LS_root/mounts/clusters/dhbwmlc-ds12-v2/code/Users/svenlangenecker/viznet-master/raw' # path to the raw data\n",
    "os.environ['SHERLOCKPATH'] = os.environ['BASEPATH']+'\\\\sherlock'\n",
    "os.environ['EXTRACTPATH'] = os.environ['BASEPATH']+'\\\\extract'\n",
    "#os.environ['PYTHONPATH'] = os.environ['PYTHONPATH']+':'+os.environ['SHERLOCKPATH']\n",
    "#os.environ['PYTHONPATH'] = os.environ['PYTHONPATH']+':'+os.environ['BASEPATH']\n",
    "os.environ['TYPENAME'] = 'type78'\n",
    "\n",
    "distance_threshold = 0.1\n",
    "current_corpus = \"public_bi\"\n",
    "\n",
    "#for index,percent in enumerate(np.arange(5,55,5)):\n",
    "#for index, percent in enumerate([1,2,3,4,6,7,8,9,10,15,20,25,30,35,40,45,50]):\n",
    "for index, percent in enumerate([1,2,3,4,5]):\n",
    "    #for distance_threshold in [1e-10,1e-9,1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e-0]:\n",
    "    for distance_threshold in [1e-4]:\n",
    "        # if index > 0:\n",
    "        #     break\n",
    "        comment = f\"embclus_without_knn_{distance_threshold}_labeled{percent}_unlabeledAbsolute_test{20.0}\"\n",
    "        column_level_split_file_path = f\"D:\\\\semantic_data_lake\\\\semantic_data_lake\\\\data\\\\extract\\\\out\\\\labeled_unlabeled_test_split\\\\{current_corpus}_{percent}_absolute_20.0.json\"\n",
    "        #embclus_gen_train_data_path = f\"D:\\\\semantic_data_lake\\\\semantic_data_lake\\\\emb_clus\\\\knn_classifier\\\\out\\\\gen_training_data\\\\public_bi_gen_training_data_1_{distance_threshold}_{percent}_absolute_20.0.csv\"\n",
    "        embclus_gen_train_data_path = f\"D:\\\\semantic_data_lake\\\\semantic_data_lake\\\\emb_clus\\\\without_knn\\\\out\\\\gen_training_data\\\\{current_corpus}_gen_training_data_{distance_threshold}_{percent}_absolute_20.0.csv\"\n",
    "        pretrained_shelock_path = f\"sherlock_retrain_embclus_without_knn_{distance_threshold}_labeled{percent}_unlabeledAbsolute_test{20.0}.pt\"\n",
    "        pretrained_CRF_LDA_path = f\"CRF+LDA_retrain_embclus_without_knn_{distance_threshold}_labeled{percent}_unlabeledAbsolute_test{20.0}.pt\"\n",
    "        \n",
    "        # retrain sherlock\n",
    "        %run ../model/train_sherlock.py -c ../model/params/public_bi/sherlock_retrain.txt --comment {comment} --column_level_split_file_path {column_level_split_file_path} --embclus_gen_train_data_path {embclus_gen_train_data_path}\n",
    "        #%run ../model/train_sherlock.py -c ../model/params/public_bi/sherlock_retrain.txt --comment {comment} --column_level_split_file_path {column_level_split_file_path}\n",
    "\n",
    "        # retrain sato\n",
    "        %run ../model/train_CRF_LC.py -c ../model/params/public_bi/CRF+LDA_retrain.txt --pre_trained_sherlock_path {pretrained_shelock_path} --comment {comment} --column_level_split_file_path {column_level_split_file_path} --embclus_gen_train_data_path {embclus_gen_train_data_path}\n",
    "        #%run ../model/train_CRF_LC.py -c ../model/params/public_bi/CRF+LDA_retrain.txt --pre_trained_sherlock_path {pretrained_shelock_path} --comment {comment} --column_level_split_file_path {column_level_split_file_path}\n",
    "        # validate sato\n",
    "        %run ../model/train_CRF_LC.py -c ../model/params/public_bi/CRF+LDA_eval.txt --model_list {pretrained_CRF_LDA_path} --comment {\"eval_\"+comment} --column_level_split_file_path {column_level_split_file_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\20120321_DHBW_AzureML\\sato\\sven\\run_exp_4_without_knn_combinedLfs.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m                 \u001b[1;31m# retrain sherlock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m                 os.system(\n\u001b[1;32m---> 44\u001b[1;33m                     \u001b[1;34mf\"python ../model/train_sherlock.py -c ../model/params/{corpus}/sherlock_retrain.txt --comment {comment} --column_level_split_file_path {column_level_split_file_path} --embclus_gen_train_data_path {embclus_gen_train_data_path}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m                 )\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%run run_exp_4_without_knn_combinedLfs.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b27a53400a11b77b02f1d2309c8bc5e534ca1e422654b13082ae5af4dd3feced"
  },
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('sato': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
