{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WORKING_DIR\"] = \"D:\\\\semantic_data_lake\\\\semantic_data_lake\"\n",
    "\n",
    "for labeled_data_size in [1,2]:\n",
    "    for distance_threshold in [1e-10,1e-9,1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e-0]:\n",
    "        %run cluster_n_classify.py --distance_threshold {distance_threshold} --labeled_data_size {labeled_data_size} --unlabeled_data_size {100-20-labeled_data_size} --test_data_size 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with absolute numbers and gen train data\n",
    "\n",
    "import os\n",
    "os.environ[\"WORKING_DIR\"] = \"D:\\\\semantic_data_lake\\\\semantic_data_lake\"\n",
    "\n",
    "for labeled_data_size in [2,3,4,5]:\n",
    "    for distance_threshold in [1e-2]:\n",
    "        %run cluster_n_classify.py --word_embedding \"gittables-abstraction-tables_1.0_df.p\" --gen_train_data True --validation_on \"unlabeled\" --corpus \"gittables-abstraction-tables\" --valid_headers \"gittables-abstraction-tables_type_gittables_abstraction_header_valid.json\" --distance_threshold {distance_threshold} --labeled_data_size {labeled_data_size} --absolute_numbers True --test_data_size 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# combine different results from multiple runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "corpus = \"turl\"\n",
    "\n",
    "#labeled_data_size = 5\n",
    "distance_threshold = 0.01\n",
    "for labeled_data_size in [1,2,3,4,5]:\n",
    "    path = join(\n",
    "        os.environ[\"WORKING_DIR\"], \"emb_clus\", \"without_knn\", \"out\",\n",
    "        f\"{corpus}_clustering_n_classify_results_gen_train_data_{distance_threshold}_{labeled_data_size}_absolute_20.0\"\n",
    "    )\n",
    "    scores = {\n",
    "        \"f1-scores_macro\": [],\n",
    "        \"precisions_macro\":[],\n",
    "        \"recalls_macro\":[],\n",
    "        \"supports_macro\": [],\n",
    "        \"f1-scores_weighted\": [],\n",
    "        \"precisions_weighted\": [],\n",
    "        \"recalls_weighted\": [],\n",
    "        \"supports_weighted\": []\n",
    "    }\n",
    "\n",
    "\n",
    "    for random_state in [1,2,3,4,5]:\n",
    "        df_current = pd.read_csv(path+f\"_{random_state}.csv\")\n",
    "        df_current = df_current[(df_current[\"already_labeled\"] == False) & (df_current[\"predicted_type\"] != \"None\")]\n",
    "        current_class_report = classification_report(df_current[\"semanticType\"],df_current[\"predicted_type\"], output_dict=True)\n",
    "        for metric in [\"macro\",\"weighted\"]:\n",
    "            scores[f\"f1-scores_{metric}\"].append(current_class_report[f\"{metric} avg\"][\"f1-score\"])\n",
    "            scores[f\"precisions_{metric}\"].append(current_class_report[f\"{metric} avg\"][\"precision\"])\n",
    "            scores[f\"recalls_{metric}\"].append(current_class_report[f\"{metric} avg\"][\"recall\"])\n",
    "            scores[f\"supports_{metric}\"].append(current_class_report[f\"{metric} avg\"][\"support\"])\n",
    "\n",
    "    df_scores = pd.DataFrame(\n",
    "        np.array([\n",
    "            scores[\"f1-scores_macro\"], scores[\"precisions_macro\"],\n",
    "            scores[\"recalls_macro\"], scores[\"supports_macro\"],\n",
    "            scores[\"f1-scores_weighted\"], scores[\"precisions_weighted\"],\n",
    "            scores[\"recalls_weighted\"], scores[\"supports_weighted\"]\n",
    "        ]), index=scores.keys())\n",
    "    df_scores[\"mean\"] = df_scores.mean(axis=1)\n",
    "    df_scores[\"std\"] = df_scores.std(axis=1)\n",
    "    df_scores[\"var\"] = df_scores.var(axis=1)\n",
    "\n",
    "    df_scores.to_csv(path+\"_mean.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "#labeled_data_size = 5\n",
    "distance_threshold = 0.01\n",
    "for labeled_data_size in [1,2,3,4,5]:\n",
    "    path = join(\n",
    "        os.environ[\"WORKING_DIR\"], \"emb_clus\", \"without_knn\", \"out\", \"validation\",\n",
    "        f\"public_bi_classification_report_test_{distance_threshold}_{labeled_data_size}_absolute_20.0\"\n",
    "    )\n",
    "    scores = {\n",
    "        \"f1-scores_macro\": [],\n",
    "        \"precisions_macro\":[],\n",
    "        \"recalls_macro\":[],\n",
    "        \"supports_macro\": [],\n",
    "        \"f1-scores_weighted\": [],\n",
    "        \"precisions_weighted\": [],\n",
    "        \"recalls_weighted\": [],\n",
    "        \"supports_weighted\": []\n",
    "    }\n",
    "\n",
    "\n",
    "    for random_state in [1,2,3,4,5]:\n",
    "        with open(path+f\"_{random_state}.json\") as f:\n",
    "            current_class_report = json.load(f)\n",
    "        for metric in [\"macro\",\"weighted\"]:\n",
    "            scores[f\"f1-scores_{metric}\"].append(current_class_report[f\"{metric} avg\"][\"f1-score\"])\n",
    "            scores[f\"precisions_{metric}\"].append(current_class_report[f\"{metric} avg\"][\"precision\"])\n",
    "            scores[f\"recalls_{metric}\"].append(current_class_report[f\"{metric} avg\"][\"recall\"])\n",
    "            scores[f\"supports_{metric}\"].append(current_class_report[f\"{metric} avg\"][\"support\"])\n",
    "\n",
    "    df_scores = pd.DataFrame(\n",
    "        np.array([\n",
    "            scores[\"f1-scores_macro\"], scores[\"precisions_macro\"],\n",
    "            scores[\"recalls_macro\"], scores[\"supports_macro\"],\n",
    "            scores[\"f1-scores_weighted\"], scores[\"precisions_weighted\"],\n",
    "            scores[\"recalls_weighted\"], scores[\"supports_weighted\"]\n",
    "        ]), index=scores.keys())\n",
    "    df_scores[\"mean\"] = df_scores.mean(axis=1)\n",
    "    df_scores[\"std\"] = df_scores.std(axis=1)\n",
    "    df_scores[\"var\"] = df_scores.var(axis=1)\n",
    "\n",
    "    df_scores.to_csv(path+\"_mean.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1-scores_macro</th>\n",
       "      <td>0.699386</td>\n",
       "      <td>0.719666</td>\n",
       "      <td>0.684844</td>\n",
       "      <td>0.686423</td>\n",
       "      <td>0.720211</td>\n",
       "      <td>0.702106</td>\n",
       "      <td>0.015411</td>\n",
       "      <td>0.067562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precisions_macro</th>\n",
       "      <td>0.640062</td>\n",
       "      <td>0.694390</td>\n",
       "      <td>0.664520</td>\n",
       "      <td>0.682944</td>\n",
       "      <td>0.682278</td>\n",
       "      <td>0.672839</td>\n",
       "      <td>0.018969</td>\n",
       "      <td>0.061378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recalls_macro</th>\n",
       "      <td>0.862954</td>\n",
       "      <td>0.864242</td>\n",
       "      <td>0.828348</td>\n",
       "      <td>0.857437</td>\n",
       "      <td>0.855749</td>\n",
       "      <td>0.853746</td>\n",
       "      <td>0.013097</td>\n",
       "      <td>0.101099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>supports_macro</th>\n",
       "      <td>285.000000</td>\n",
       "      <td>285.000000</td>\n",
       "      <td>285.000000</td>\n",
       "      <td>285.000000</td>\n",
       "      <td>285.000000</td>\n",
       "      <td>285.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11603.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-scores_weighted</th>\n",
       "      <td>0.425527</td>\n",
       "      <td>0.454331</td>\n",
       "      <td>0.371715</td>\n",
       "      <td>0.364884</td>\n",
       "      <td>0.393615</td>\n",
       "      <td>0.402014</td>\n",
       "      <td>0.033637</td>\n",
       "      <td>0.020329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precisions_weighted</th>\n",
       "      <td>0.383635</td>\n",
       "      <td>0.435312</td>\n",
       "      <td>0.362162</td>\n",
       "      <td>0.384603</td>\n",
       "      <td>0.371269</td>\n",
       "      <td>0.387396</td>\n",
       "      <td>0.025356</td>\n",
       "      <td>0.019260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recalls_weighted</th>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.547368</td>\n",
       "      <td>0.452632</td>\n",
       "      <td>0.438596</td>\n",
       "      <td>0.477193</td>\n",
       "      <td>0.489825</td>\n",
       "      <td>0.043293</td>\n",
       "      <td>0.030046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>supports_weighted</th>\n",
       "      <td>285.000000</td>\n",
       "      <td>285.000000</td>\n",
       "      <td>285.000000</td>\n",
       "      <td>285.000000</td>\n",
       "      <td>285.000000</td>\n",
       "      <td>285.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11603.571429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              0           1           2           3  \\\n",
       "f1-scores_macro        0.699386    0.719666    0.684844    0.686423   \n",
       "precisions_macro       0.640062    0.694390    0.664520    0.682944   \n",
       "recalls_macro          0.862954    0.864242    0.828348    0.857437   \n",
       "supports_macro       285.000000  285.000000  285.000000  285.000000   \n",
       "f1-scores_weighted     0.425527    0.454331    0.371715    0.364884   \n",
       "precisions_weighted    0.383635    0.435312    0.362162    0.384603   \n",
       "recalls_weighted       0.533333    0.547368    0.452632    0.438596   \n",
       "supports_weighted    285.000000  285.000000  285.000000  285.000000   \n",
       "\n",
       "                              4        mean       std           var  \n",
       "f1-scores_macro        0.720211    0.702106  0.015411      0.067562  \n",
       "precisions_macro       0.682278    0.672839  0.018969      0.061378  \n",
       "recalls_macro          0.855749    0.853746  0.013097      0.101099  \n",
       "supports_macro       285.000000  285.000000  0.000000  11603.571429  \n",
       "f1-scores_weighted     0.393615    0.402014  0.033637      0.020329  \n",
       "precisions_weighted    0.371269    0.387396  0.025356      0.019260  \n",
       "recalls_weighted       0.477193    0.489825  0.043293      0.030046  \n",
       "supports_weighted    285.000000  285.000000  0.000000  11603.571429  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
